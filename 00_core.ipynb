{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-29T18:16:10.546Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAseq Pipelines using Dask and Prefect\n",
    "\n",
    "> A framework for processing RNAseq data using Dask/Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:24:07.673467Z",
     "start_time": "2021-03-30T20:24:07.297692Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:24:09.655034Z",
     "start_time": "2021-03-30T20:24:09.650832Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide \n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:21:43.204327Z",
     "start_time": "2021-03-31T00:21:43.118562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_hdict.ipynb.\n",
      "Converted 02_seqs.ipynb.\n",
      "Converted 03_utils.ipynb.\n",
      "Converted 04_builtins.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:20:52.731796Z",
     "start_time": "2021-03-30T20:20:52.708021Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:20:53.464632Z",
     "start_time": "2021-03-30T20:20:53.456264Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline elements (Tasks)\n",
    "\n",
    "- Unit of execution (node). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T21:05:41.777086Z",
     "start_time": "2021-03-30T21:05:41.769461Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# use format from previously made pipeline\n",
    "# inputs\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import socket\n",
    "import glob\n",
    "from itertools import groupby\n",
    "\n",
    "import numpy as N\n",
    "import pandas as PD\n",
    "\n",
    "import paramiko\n",
    "import prefect\n",
    "from prefect import task, Flow, Parameter, unmapped, case\n",
    "from prefect.engine import signals\n",
    "from prefect.tasks import Task\n",
    "\n",
    "from dask_rnaseq.utils import *\n",
    "from dask_rnaseq.hdict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T01:21:30.560923Z",
     "start_time": "2021-04-01T01:21:30.521296Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# A pipeline is a Prefect Flow which consists of Prefect Tasks (Analysis Tasks).\n",
    "# A pipeline accepts site config and a list samples. \n",
    "# A site config is a site specific relatively constant config info, such as paths, exec info. \n",
    "# A list of samples changes each time and each sample contains \n",
    "#  1) sample id (sid), 2) input files, 3) destination location for saving analysis results.\n",
    "\n",
    "\n",
    "class FileInFileOut(Task):\n",
    "    \"\"\"\n",
    "    Inputs and outputs (and temporary files) are defined by files.\n",
    "    \"\"\"\n",
    "    nickname = 'analysis' # program name\n",
    "    i_tmpls = dict(\n",
    "        r1 = '{r1}',\n",
    "        r2 = '{r2}',\n",
    "    )\n",
    "    o_tmpls = {}\n",
    "    t_tmpls = {}\n",
    "              \n",
    "    def __init__(self, cfg, tag=None, **kw):\n",
    "        self.tag = tag\n",
    "        self.pname = f'{self.nickname}.{tag}' if tag else f'{self.nickname}'\n",
    "        self.cfg = cfg\n",
    "        self.set_param({})\n",
    "        super().__init__(**kw)        \n",
    "        \n",
    "    def set_param(self, param, cfg=None):\n",
    "        # copy and setup convenience access\n",
    "        if cfg is not None:\n",
    "            self.cfg = cfg\n",
    "        self.param = HBox(param.copy())\n",
    "        self.p = self.cfg.merge(param)\n",
    "        self.pcfg = self.p.overridden(self.pname)\n",
    "        self._prep_dstdir()\n",
    "        self._define_files()        \n",
    "        return self.p\n",
    "\n",
    "    def _prep_dstdir(self):\n",
    "        \"Prepare program output directory.\"\n",
    "        p = self.p\n",
    "        # destination directory: Output dir/DatasetID/progname.tag\n",
    "        ddir = os.path.join(p.odir, p.did, self.pname)\n",
    "        mkdirs(ddir)\n",
    "        p.dstdir = self.dstdir = ddir\n",
    "        # prefix = {destdir}/SampleID\n",
    "        p.prefix = self.prefix = os.path.join(ddir, p.sid)  \n",
    "        \n",
    "    def _define_files(self):\n",
    "        p = self.p\n",
    "        self.inps = {k: v.format(**p) for k, v in self.i_tmpls.items()}\n",
    "        self.outs = {k: v.format(**p) for k, v in self.o_tmpls.items()}\n",
    "        self.tmps = {k: v.format(**p) for k, v in self.t_tmpls.items()}\n",
    "                \n",
    "    def check_files(self):\n",
    "        skip = False\n",
    "        force = self.p.get('force', False)\n",
    "        signalskip = self.p.get('signalskip',True)\n",
    "        # check input exists\n",
    "        for k,f in self.inps.items():\n",
    "            if not os.path.exists(f):\n",
    "                raise signals.FAIL(message=f'input file {k}:{f} does not exist')\n",
    "        done = all([os.path.exists(x) for k,x in self.outs.items()])\n",
    "        # if force delete tmps and outs\n",
    "        if force or (not done): # delete all existing\n",
    "            deletefiles(list(self.tmps.values())+list(self.outs.values()))\n",
    "            # if all outs exists then skip\n",
    "        elif done:\n",
    "            deletefiles(list(self.tmps.values()))\n",
    "            if signalskip:\n",
    "                raise signals.SKIP(message=f'all outputs {self.outs} already exist')\n",
    "            skip = True\n",
    "        return skip\n",
    "\n",
    "    def modify_param(self, skip=False):\n",
    "        self._modify_param_common(skip)\n",
    "        self._modify_param_specific(skip)\n",
    "        return self.param\n",
    "    \n",
    "    def _modify_param_common(self, skip=False):\n",
    "        p = self.param\n",
    "        pname = self.pname\n",
    "        outs = self.outs\n",
    "        if skip:\n",
    "            inps = self.inps\n",
    "            tmps = self.tmps\n",
    "        else:\n",
    "            inps = self._inps # ramdisk\n",
    "            tmps = self._tmps # ramdisk\n",
    "        p[f'{pname}.dstdir'] = self.dstdir\n",
    "        p[f'{pname}.prefix'] = self.prefix\n",
    "        p[f'{pname}.inputs'] = [os.path.basename(x) for k,x in inps.items()]\n",
    "        p[f'{pname}.outputs'] = [os.path.basename(x) for k,x in outs.items()]\n",
    "        p[f'{pname}.temps'] = [os.path.basename(x) for k,x in tmps.items()]\n",
    "        p[f'info.{pname}'] = self._read_stats()\n",
    "        p.history = pname if p.get('history','')=='' else f'{p.history}|{pname}'\n",
    "        if skip:\n",
    "            p[f'{pname}.skipped'] = True\n",
    "            \n",
    "    def _modify_param_specific(self,skip=False):\n",
    "        pass\n",
    "    \n",
    "    def _read_stats(self):\n",
    "        return {}\n",
    "        \n",
    "    def nfs_to_ramdisk(self):\n",
    "        \"Copy and decompress files to local RAMDISK\"\n",
    "        p = self.p\n",
    "        ramdisk = p.get('ramdisk','')\n",
    "        nfs = p.get('nfs','')\n",
    "        inps = self.inps\n",
    "        tmps = self.tmps\n",
    "        outs = self.outs\n",
    "        ppre = self.prefix\n",
    "        if (not ramdisk) or (nfs==ramdisk):\n",
    "            # don't move\n",
    "            self._inps = inps\n",
    "            self._tmps = tmps\n",
    "            self._outs = outs\n",
    "            self._prefix = ppre\n",
    "            return\n",
    "        # inps\n",
    "        delete = []\n",
    "        host = get_hostname()\n",
    "        nfslocal = (host==p.nfshost)\n",
    "        def _nfs_to_ramdisk_copy(dic):\n",
    "            rslt = []\n",
    "            for k,src in dic.items():\n",
    "                if src.startswith(nfs):\n",
    "                    if nfslocal: # don't copy if local\n",
    "                        dst = src\n",
    "                    else:\n",
    "                        dst = src.replace(nfs, ramdisk)\n",
    "                    if not os.path.exists(dst):\n",
    "                        mkdirs(os.path.dirname(dst))\n",
    "                        if src != dst:\n",
    "                            shutil.copyfile(src,dst)\n",
    "                            print('********** NFS => RAMDISK *********************************')\n",
    "                            print(f'{src}=>{host}:{dst}')\n",
    "                            print('***********************************************************')\n",
    "                            delete.append((host,dst))\n",
    "                    rslt.append((k,dst))\n",
    "                else:\n",
    "                    rslt.append((k,src))\n",
    "            return dict(rslt)\n",
    "        def _nfs_to_ramdisk_path(dic):\n",
    "            rslt = dict([(k,x.replace(nfs,ramdisk)) for k,x in dic.items()])\n",
    "            deletefiles(list(rslt.values())) # clean destination\n",
    "            return rslt\n",
    "        self._inps  = _nfs_to_ramdisk_copy(inps)\n",
    "        self._tmps   = _nfs_to_ramdisk_path(tmps)\n",
    "        self._outs = _nfs_to_ramdisk_path(outs)\n",
    "        self._prefix = ppre.replace(nfs,ramdisk)\n",
    "        mkdirs(os.path.dirname(self._prefix))\n",
    "        self.param.delete = self.param.get('delete',[]) + delete # copied to ramdisk\n",
    "    \n",
    "    def ramdisk_to_nfs(self, delete_outs1=False):\n",
    "        \"\"\"\n",
    "        Move outputs from local RAMDISK (srcdir) to NFS (dstdir),\n",
    "        delete other files used in RAMDISK.\n",
    "        \"\"\"\n",
    "        p = self.p\n",
    "        nfs = p.get('nfs','')\n",
    "        ramdisk = p.get('ramdisk','')\n",
    "        inps = self.inps\n",
    "        inps1 = self._inps\n",
    "        tmps1 = self._tmps\n",
    "        outs1 = self._outs\n",
    "        if (not ramdisk) or (nfs==ramdisk): # no op\n",
    "            return \n",
    "        delete = []\n",
    "        host = socket.gethostname()\n",
    "        for k,src in outs1.items():\n",
    "            if src.startswith(ramdisk):\n",
    "                dst = src.replace(ramdisk, nfs)\n",
    "                try:\n",
    "                    mkdirs(os.path.dirname(dst))\n",
    "                    if src != dst:\n",
    "                        shutil.copyfile(src,dst)\n",
    "                        os.chmod(dst, 0o660)\n",
    "                        if delete_outs1:\n",
    "                            os.unlink(src)\n",
    "                        else:\n",
    "                            delete.append((host,src))\n",
    "                        print('********** RAMDISK => NFS *********************************')\n",
    "                        print(f'{host}:{src}=>{dst}')\n",
    "                        print('***********************************************************')\n",
    "                except:\n",
    "                    raise signals.FAIL(message=f'shutil.copy {src} to {dst} failed.')\n",
    "        # delete tmps1 regardless\n",
    "        deletefiles(tmps1.values())\n",
    "        # delete inps1 if not original\n",
    "        tgts = [inps1[k] for k in inps1 if inps[k]!=inps1[k]]\n",
    "        deletefiles(tgts)\n",
    "        # delete later\n",
    "        self.param.delete = self.param.get('delete',[]) + delete\n",
    "    \n",
    "    def _run(self):\n",
    "        pass\n",
    "    \n",
    "    def get_nthreads(self, progname=None)->int:\n",
    "        # return num of max threads\n",
    "        ntmax = self.p.get('maxthreads', 8)\n",
    "        if (progname is None) or (progname == self.pname):\n",
    "            ntprg = self.pcfg.get('nthreads',ntmax)\n",
    "        else:\n",
    "            ntprg = self.p.overridden(progname).get('nthreads',ntmax)\n",
    "        return min(ntmax, ntprg)\n",
    "\n",
    "    def compress(self, files):\n",
    "        if isinstance(files, dict):\n",
    "            files = files.values()\n",
    "        # compress with pigz\n",
    "        pigz = self.p.pigz.execpath\n",
    "        nt = self.p.pigz.get('nthreads',self.p.get('maxthreads',8))\n",
    "        for f in files:\n",
    "            subprocesscall(f'{pigz} -p {nt} --fast {f}')\n",
    "                \n",
    "    def run(self, param):\n",
    "        \"\"\"\n",
    "        Common pattern in analysis:\n",
    "            1. setup destination directory\n",
    "            2. check files (already done?)\n",
    "            3. transfer files (between machines)\n",
    "        \n",
    "        Override \n",
    "            1. _define_files\n",
    "            2. _run\n",
    "            3. _modify_param_specific\n",
    "            4. _read_stats\n",
    "        \"\"\"\n",
    "        self.set_param(param)\n",
    "        if self.check_files(): # skip?\n",
    "            return self.modify_param(skip=True)\n",
    "        self.nfs_to_ramdisk()\n",
    "        self._run()\n",
    "        self.ramdisk_to_nfs()\n",
    "        return self.modify_param(skip=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:25:34.954493Z",
     "start_time": "2021-03-30T20:25:34.948238Z"
    }
   },
   "outputs": [],
   "source": [
    "# test config\n",
    "import socket\n",
    "\n",
    "cfg = HBox.from_toml(f\"\"\"\n",
    "nfs = './tests'\n",
    "ramdisk = './tests2'\n",
    "odir = './tests/outputs'\n",
    "idir = './tests'\n",
    "nfshost = 'host1'\n",
    "sshuser = 'user1'\n",
    "workers = ['host1']\n",
    "force = true\n",
    "did = 'datasetid'\n",
    "maxthreads = 8\n",
    "\n",
    "[analysis]\n",
    "execpath = 'nonexistent'\n",
    "\n",
    "[analysis.tag]\n",
    "extra = 'param1'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:20:59.091348Z",
     "start_time": "2021-03-30T20:20:59.058123Z"
    }
   },
   "outputs": [],
   "source": [
    "pn = PipelineNode('tag', cfg)\n",
    "assert(pn.tag=='tag')\n",
    "assert(pn.pname=='analysis.tag')\n",
    "assert(pn.pcfg.execpath=='nonexistent')\n",
    "assert(pn.pcfg.extra=='param1')\n",
    "assert(pn.cfg.did=='datasetid')\n",
    "assert(pn.pcfg.did=='datasetid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:23.577328Z",
     "start_time": "2021-03-30T18:51:23.546463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfs = \"./tests\"\n",
      "ramdisk = \"./tests2\"\n",
      "odir = \"./tests/outputs\"\n",
      "idir = \"./tests\"\n",
      "nfshost = \"host1\"\n",
      "sshuser = \"user1\"\n",
      "workers = [ \"host1\",]\n",
      "force = true\n",
      "did = \"datasetid\"\n",
      "maxthreads = 8\n",
      "\n",
      "[analysis]\n",
      "execpath = \"nonexistent\"\n",
      "\n",
      "[analysis.tag]\n",
      "extra = \"param1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:23.997676Z",
     "start_time": "2021-03-30T18:51:23.967691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:24.560555Z",
     "start_time": "2021-03-30T18:51:24.530570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfs = \"./tests\"\n",
      "ramdisk = \"./tests2\"\n",
      "odir = \"./tests/outputs\"\n",
      "idir = \"./tests\"\n",
      "nfshost = \"host1\"\n",
      "sshuser = \"user1\"\n",
      "workers = [ \"host1\",]\n",
      "force = true\n",
      "did = \"datasetid\"\n",
      "maxthreads = 8\n",
      "execpath = \"nonexistent\"\n",
      "extra = \"param1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:26.383239Z",
     "start_time": "2021-03-30T18:51:26.352459Z"
    }
   },
   "outputs": [],
   "source": [
    "pn.set_param(HBox({'sid':'sample1'}))\n",
    "pn._prep_dstdir()\n",
    "assert(os.path.exists('./tests/outputs/datasetid/analysis.tag'))\n",
    "assert(pn.prefix == './tests/outputs/datasetid/analysis.tag/sample1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:26.755670Z",
     "start_time": "2021-03-30T18:51:26.725517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sid = \"sample1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:27.494409Z",
     "start_time": "2021-03-30T18:51:27.463362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfs = \"./tests\"\n",
      "ramdisk = \"./tests2\"\n",
      "odir = \"./tests/outputs\"\n",
      "idir = \"./tests\"\n",
      "nfshost = \"host1\"\n",
      "sshuser = \"user1\"\n",
      "workers = [ \"host1\",]\n",
      "force = true\n",
      "did = \"datasetid\"\n",
      "maxthreads = 8\n",
      "sid = \"sample1\"\n",
      "\n",
      "[analysis]\n",
      "execpath = \"nonexistent\"\n",
      "\n",
      "[analysis.tag]\n",
      "extra = \"param1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:29.906159Z",
     "start_time": "2021-03-30T18:51:29.875644Z"
    }
   },
   "outputs": [],
   "source": [
    "pn._define_files()\n",
    "assert(pn.inps=={})\n",
    "assert(len(pn.outs)==0)\n",
    "assert(len(pn.tmps)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:30.505094Z",
     "start_time": "2021-03-30T18:51:30.477041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sid = \"sample1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:31.599948Z",
     "start_time": "2021-03-30T18:51:31.570810Z"
    }
   },
   "outputs": [],
   "source": [
    "pn.inps = {'r1':'./tests/5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz',\n",
    "           'r2':'./tests/5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:32.054121Z",
     "start_time": "2021-03-30T18:51:32.023258Z"
    }
   },
   "outputs": [],
   "source": [
    "assert(pn._check_files()==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:32.675491Z",
     "start_time": "2021-03-30T18:51:32.644482Z"
    }
   },
   "outputs": [],
   "source": [
    "pn._modify_param_common(skip=True)\n",
    "assert(pn.param.to_toml()==\\\n",
    "\"\"\"sid = \"sample1\"\n",
    "history = \"analysis.tag\"\n",
    "\n",
    "[analysis.tag]\n",
    "dstdir = \"./tests/outputs/datasetid/analysis.tag\"\n",
    "prefix = \"./tests/outputs/datasetid/analysis.tag/sample1\"\n",
    "inputs = [ \"5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz\", \"5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz\",]\n",
    "outputs = []\n",
    "temps = []\n",
    "skipped = true\n",
    "\n",
    "[info.analysis.tag]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:41.670896Z",
     "start_time": "2021-03-30T18:51:41.639763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sid = \"sample1\"\n",
      "history = \"analysis.tag|analysis.tag\"\n",
      "\n",
      "[analysis.tag]\n",
      "dstdir = \"./tests/outputs/datasetid/analysis.tag\"\n",
      "prefix = \"./tests/outputs/datasetid/analysis.tag/sample1\"\n",
      "inputs = [ \"5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz\", \"5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz\",]\n",
      "outputs = []\n",
      "temps = []\n",
      "skipped = true\n",
      "\n",
      "[info.analysis.tag]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pn._modify_param_common(skip=True)\n",
    "ptoml(pn.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:46.548745Z",
     "start_time": "2021-03-30T18:51:46.516645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfs = \"./tests\"\n",
      "ramdisk = \"./tests2\"\n",
      "odir = \"./tests/outputs\"\n",
      "idir = \"./tests\"\n",
      "nfshost = \"host1\"\n",
      "sshuser = \"user1\"\n",
      "workers = [ \"host1\",]\n",
      "force = true\n",
      "did = \"datasetid\"\n",
      "maxthreads = 8\n",
      "sid = \"sample1\"\n",
      "\n",
      "[analysis]\n",
      "execpath = \"nonexistent\"\n",
      "\n",
      "[analysis.tag]\n",
      "extra = \"param1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:51:49.224230Z",
     "start_time": "2021-03-30T18:51:49.194120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfs = \"./tests\"\n",
      "ramdisk = \"./tests2\"\n",
      "odir = \"./tests/outputs\"\n",
      "idir = \"./tests\"\n",
      "nfshost = \"host1\"\n",
      "sshuser = \"user1\"\n",
      "workers = [ \"host1\",]\n",
      "force = true\n",
      "did = \"datasetid\"\n",
      "maxthreads = 8\n",
      "sid = \"sample1\"\n",
      "execpath = \"nonexistent\"\n",
      "extra = \"param1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ptoml(pn.pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:52:42.412711Z",
     "start_time": "2021-03-30T18:52:42.255714Z"
    }
   },
   "outputs": [],
   "source": [
    "rm -rf ./tests2/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:52:43.948047Z",
     "start_time": "2021-03-30T18:52:43.909921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** NFS => RAMDISK *********************************\n",
      "./tests/5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz=>suginok-p1:./tests2/5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz\n",
      "***********************************************************\n",
      "********** NFS => RAMDISK *********************************\n",
      "./tests/5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz=>suginok-p1:./tests2/5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz\n",
      "***********************************************************\n",
      "Directory ./tests2/outputs/datasetid/analysis.tag created successfully\n"
     ]
    }
   ],
   "source": [
    "pn._nfs_to_ramdisk()\n",
    "assert(len(pn._inps)==2)\n",
    "assert(pn._outs=={})\n",
    "assert(pn._tmps=={})\n",
    "host = get_hostname()\n",
    "assert(pn.param.delete==[(host, './tests2/5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz'), \n",
    "                         (host, './tests2/5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:53:06.961524Z",
     "start_time": "2021-03-30T18:53:06.930870Z"
    }
   },
   "outputs": [],
   "source": [
    "pn._ramdisk_to_nfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T18:54:59.797512Z",
     "start_time": "2021-03-30T18:54:59.765959Z"
    }
   },
   "outputs": [],
   "source": [
    "pn.param.history=''\n",
    "pn._modify_param_common()\n",
    "assert(pn.param.to_toml()==\"\"\"sid = \"sample1\"\n",
    "history = \"analysis.tag\"\n",
    "delete = [ [ \"suginok-p1\", \"./tests2/5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz\",], [ \"suginok-p1\", \"./tests2/5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz\",],]\n",
    "\n",
    "[analysis.tag]\n",
    "dstdir = \"./tests/outputs/datasetid/analysis.tag\"\n",
    "prefix = \"./tests/outputs/datasetid/analysis.tag/sample1\"\n",
    "inputs = [ \"5d_GH146mtdT_PN_Lee_L1_S69_R1_001.fastq.gz\", \"5d_GH146mtdT_PN_Lee_L1_S69_R2_001.fastq.gz\",]\n",
    "outputs = []\n",
    "temps = []\n",
    "skipped = true\n",
    "\n",
    "[info.analysis.tag]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to run single task on multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T02:45:10.789305Z",
     "start_time": "2021-03-30T02:45:10.782791Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_task(task, params, executor, **kw):\n",
    "    name = task.run.__name__\n",
    "    with Flow(name) as flow:\n",
    "        p1 = task.map(p=params,**kw)\n",
    "    rslt = flow.run(executor=executor)\n",
    "    info = rslt.result[flow.get_tasks(name)[0]].result\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:02:09.510630Z",
     "start_time": "2021-03-30T23:02:09.493112Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@task\n",
    "def clean_ramdisk_local(p):\n",
    "    host = get_hostname()\n",
    "    tgts = p.get('delete',[])\n",
    "    others = []\n",
    "    for h,f in tgts:\n",
    "        if (h==host):\n",
    "            if os.path.exists(f):\n",
    "                os.unlink(f)\n",
    "                print(f'CLEANED:{h}:{f}')\n",
    "        else:\n",
    "            others.append((h,f))\n",
    "            print(f'OTHER HOST:{h}:{f}')\n",
    "    p.delete = others\n",
    "    if 'dummy' in p:\n",
    "        p.dummy = '' # clear dummy data\n",
    "    return p\n",
    "\n",
    "@task\n",
    "def clean_ramdisk_global(ps, cfg):\n",
    "    tgts = [x for p in ps for x in p.get('delete',[])]\n",
    "    if len(tgts)==0:\n",
    "        return ps\n",
    "    # groupby host\n",
    "    key = lambda x:x[0]\n",
    "    grp = {k:list(g) for k,g in groupby(sorted(tgts, key=key), key=key)}\n",
    "    host = get_hostname()\n",
    "    # for each remote host use paramiko to delete\n",
    "    remained = []\n",
    "    for h in grp.keys():\n",
    "        files = list(set([x[1] for x in grp[h]]))\n",
    "        if h!=host:\n",
    "            remain = remote_remove_files(h, files, cfg.sshuser)\n",
    "            remained += [(h,f) for f in remain]\n",
    "        else:# delete local\n",
    "            deletefiles(files)\n",
    "            print(f'LOCAL CLEAN: {h}\\n','\\n  '.join(files))\n",
    "    p[0].delete = remained\n",
    "    for p in ps[1:]:\n",
    "        p.delete = []\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:02:16.540989Z",
     "start_time": "2021-03-30T23:02:16.524649Z"
    }
   },
   "outputs": [],
   "source": [
    "# export\n",
    "@task\n",
    "def merge_params(p1,p2,fields):\n",
    "    \"merge parameters from two upstreams\"\n",
    "    # merge delete by default\n",
    "    p1 = p1.copy()\n",
    "    if 'delete' not in fields:\n",
    "        fields += ['delete']\n",
    "    for srcdst in fields:\n",
    "        if isinstance(srcdst,tuple):\n",
    "            src,dst = srcdst\n",
    "        else:\n",
    "            src,dst = srcdst,srcdst\n",
    "        sval = p2.get(src,None)\n",
    "        if sval is None:\n",
    "            continue\n",
    "        dval = p1.get(dst,None)\n",
    "        if dval is None: #  just set\n",
    "            p1[dst] = sval\n",
    "        else: # merge\n",
    "            if isinstance(dval,list):\n",
    "                if isinstance(sval,list):\n",
    "                    val = dval+sval\n",
    "                else:\n",
    "                    val = dval+[sval]\n",
    "            else:\n",
    "                if isinstance(sval,list):\n",
    "                    val = [dval]+sval\n",
    "                else:\n",
    "                    val = [dval, sval]    \n",
    "            #print('VAL:', val, 'dst:', dst)\n",
    "            p1[dst] = val\n",
    "    return p1\n",
    "\n",
    "@task\n",
    "def write_aggregated_info(ps,cfg,fields,fname='info.csv'):\n",
    "    odir = cfg.odir\n",
    "    out = f'{odir}/{fname}'\n",
    "    if os.path.exists(out):\n",
    "        os.unlink(out)\n",
    "    rows = [x.subset(fields) for x in ps]\n",
    "    df = PD.DataFrame(rows) \n",
    "    df.to_csv(out, sep='\\t')\n",
    "    return {'info':df, 'params':ps}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniconda4.8.3",
   "language": "python",
   "name": "mini483"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
